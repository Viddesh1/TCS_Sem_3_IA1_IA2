{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "data_dir = 'C:/IA_SEM_3/TCS_Sem_3_IA1_IA2/TCS_Sem-3/IA_2/Covid19-dataset/train'\n",
    "classes = ['Covid', 'Normal', 'Viral Pneumonia']\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size and batch size\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for class_index, class_name in enumerate(classes):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    for image_name in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image_name)\n",
    "        image = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_width, img_height))\n",
    "        image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        data.append(image)\n",
    "        labels.append(class_index)\n",
    "\n",
    "\n",
    "# Convert lists to arrays\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Convert labels to one-hot encoded format\n",
    "labels = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation and test data rescaling\n",
    "val_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "listdir: embedded null character in path",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Flow data from directories\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_generator \u001b[39m=\u001b[39m train_datagen\u001b[39m.\u001b[39;49mflow_from_directory(\n\u001b[0;32m      3\u001b[0m     train_data,\n\u001b[0;32m      4\u001b[0m     target_size\u001b[39m=\u001b[39;49m(img_width, img_height),\n\u001b[0;32m      5\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m      6\u001b[0m     class_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcategorical\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m val_generator \u001b[39m=\u001b[39m val_datagen\u001b[39m.\u001b[39mflow_from_directory(\n\u001b[0;32m     10\u001b[0m     train_data,\n\u001b[0;32m     11\u001b[0m     target_size\u001b[39m=\u001b[39m(img_width, img_height),\n\u001b[0;32m     12\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m     13\u001b[0m     class_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     16\u001b[0m test_generator \u001b[39m=\u001b[39m test_datagen\u001b[39m.\u001b[39mflow_from_directory(\n\u001b[0;32m     17\u001b[0m     val_data, \u001b[39m# Replace with test data\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     target_size\u001b[39m=\u001b[39m(img_width, img_height),\n\u001b[0;32m     19\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m     20\u001b[0m     class_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n",
      "File \u001b[1;32mc:\\IA_SEM_3\\TCS_Sem_3_IA1_IA2\\venv-test\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:1648\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1562\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflow_from_directory\u001b[39m(\n\u001b[0;32m   1563\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1564\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     keep_aspect_ratio\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1579\u001b[0m ):\n\u001b[0;32m   1580\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[0;32m   1581\u001b[0m \n\u001b[0;32m   1582\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1646\u001b[0m \u001b[39m            and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[0;32m   1647\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1648\u001b[0m     \u001b[39mreturn\u001b[39;00m DirectoryIterator(\n\u001b[0;32m   1649\u001b[0m         directory,\n\u001b[0;32m   1650\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1651\u001b[0m         target_size\u001b[39m=\u001b[39;49mtarget_size,\n\u001b[0;32m   1652\u001b[0m         color_mode\u001b[39m=\u001b[39;49mcolor_mode,\n\u001b[0;32m   1653\u001b[0m         keep_aspect_ratio\u001b[39m=\u001b[39;49mkeep_aspect_ratio,\n\u001b[0;32m   1654\u001b[0m         classes\u001b[39m=\u001b[39;49mclasses,\n\u001b[0;32m   1655\u001b[0m         class_mode\u001b[39m=\u001b[39;49mclass_mode,\n\u001b[0;32m   1656\u001b[0m         data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_format,\n\u001b[0;32m   1657\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1658\u001b[0m         shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1659\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[0;32m   1660\u001b[0m         save_to_dir\u001b[39m=\u001b[39;49msave_to_dir,\n\u001b[0;32m   1661\u001b[0m         save_prefix\u001b[39m=\u001b[39;49msave_prefix,\n\u001b[0;32m   1662\u001b[0m         save_format\u001b[39m=\u001b[39;49msave_format,\n\u001b[0;32m   1663\u001b[0m         follow_links\u001b[39m=\u001b[39;49mfollow_links,\n\u001b[0;32m   1664\u001b[0m         subset\u001b[39m=\u001b[39;49msubset,\n\u001b[0;32m   1665\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[0;32m   1666\u001b[0m         dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[0;32m   1667\u001b[0m     )\n",
      "File \u001b[1;32mc:\\IA_SEM_3\\TCS_Sem_3_IA1_IA2\\venv-test\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[0;32m    562\u001b[0m     classes \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 563\u001b[0m     \u001b[39mfor\u001b[39;00m subdir \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(directory)):\n\u001b[0;32m    564\u001b[0m         \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    565\u001b[0m             classes\u001b[39m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mValueError\u001b[0m: listdir: embedded null character in path"
     ]
    }
   ],
   "source": [
    "# Flow data from directories\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    train_data,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    val_data, # Replace with test data\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load ResNet50 with pretrained weights\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Global Average Pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a fully connected layer\n",
    "x = Dense(512, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add output layer for classification\n",
    "output = Dense(3, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=30,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // batch_size,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
